{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e25ad813",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "from numba import jit, njit, float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6607b1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Taken form the SAMoSA -Analysis library developed by Silke Henkes\n",
    "## Refer for further details https://github.com/silkehenkes/SAMoSA\n",
    "## Dated : June 2025\n",
    "\n",
    "import pandas\n",
    "import gzip\n",
    "\n",
    "class ReadData:\n",
    "  \n",
    "\tdef __init__(self, filename,dialect):\n",
    "\t\tif filename.split('.')[-1] == 'gz':\n",
    "\t\t\tnames = ['id', 'type', 'flag', 'radius', 'x','y','z', 'vx', 'vy', 'vz', 'nx', 'ny', 'nz']\n",
    "\t\t\tself.datafile = gzip.open(filename, newline='')\n",
    "\t\t\tline = self.datafile.readline()\n",
    "\t\t\tself.header_names = 0\n",
    "\t\t\tif line.startswith(\"#\"):\n",
    "\t\t\t\tself.header_names = line[1:].strip().split()\n",
    "\t\t\tself.datafile.seek(0)\t\n",
    "\n",
    "\t\telse:\n",
    "\t\t\tself.datafile = open(filename, newline='')\n",
    "\t\t\tline = self.datafile.readline()\n",
    "\t\t\tself.header_names = 0\n",
    "\t\t\tnames = ['id', 'type', 'flag', 'radius', 'x','y','z', 'vx', 'vy', 'vz', 'nx', 'ny', 'nz']\n",
    "\t\t\tif line.startswith(\"#\"):\n",
    "\t\t\t\tself.header_names = line[1:].strip().split()\n",
    "\t\t\telse:\n",
    "\t\t\t\tself.header_names = names\n",
    "\t\t\tself.datafile.seek(0)\t\n",
    "\t\tself.dialect = dialect\n",
    "\t\tself.__read_data()\n",
    "\n",
    "\t\n",
    "\n",
    "\t# Read data using pandas. Simplify data structure for Configuration\n",
    "\tdef __read_data(self):\n",
    "\t\tif self.dialect == \"SAMoS\":\n",
    "\t\t\t\n",
    "\t\t\tself.data = pandas.read_csv(self.datafile,sep=r\"\\s+\", comment= \"#\", names = self.header_names)\n",
    "\t\t\t#\n",
    "\t\t\t# temp = self.data.columns\n",
    "\t\t\t#colshift = {}\n",
    "\t\t\t#for u in range(len(temp)-1): \n",
    "\t\t\t#\tcolshift[temp[u]] = temp[u+1]\n",
    "\t\t\t#self.data.rename(columns = {temp[len(temp)-1]: 'garbage'},inplace=True)\n",
    "\t\t\t#self.data.rename(columns = colshift,inplace=True,errors=\"raise\")\n",
    "\t\t\t#print(self.data.columns)\n",
    "\t\telif self.dialect == \"CCCPy\":\n",
    "\t\t\tself.data = pandas.read_csv(self.datafile,header=0)\n",
    "\t\t\t# look of the header\n",
    "\t\t\t# currTime,xPos,yPos,xVel,yVel,polAngle,polVel,xPol,yPol,rad,glued\n",
    "\t\t\t# We need to muck about with the headers to distil this to a unified format\n",
    "\t\t\t# Classical samos header:\n",
    "\t\t\t#  id  type  flag  radius  x  y  z  vx  vy  vz  nx  ny  nz \n",
    "\t\t\tself.data.rename(columns={\"xPos\": \"x\", \"yPos\": \"y\", \"xVel\": \"vx\", \"yVel\": \"vy\", \"xPol\": \"nx\", \"yPol\": \"ny\", \"rad\":\"radius\", \"glued\":\"type\"}, inplace=True,errors=\"raise\")\n",
    "\t\t\t#print(self.data.columns)\n",
    "\t\telif self.dialect == \"CAPMD\":\n",
    "\t\t\tself.data = pandas.read_csv(self.datafile,header=0)\n",
    "\t\telse:\n",
    "\t\t\tprint(\"Unknown data format dialect!\")\n",
    "\t\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df1258b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_positions(files_path,tp):\n",
    "    # extracts the positions from the .dat file and filter for the given  type\n",
    "\n",
    "    files = sorted(glob.glob(files_path))\n",
    "\n",
    "    positions = []\n",
    "\n",
    "    for file in files:   \n",
    "        read_file = ReadData(file, \"SAMoS\")\n",
    "        read_data= read_file.data\n",
    "        data1 = read_data[read_data['type']==tp]\n",
    "        cur_positions = np.stack((data1['x'], data1['y'], data1['z'])).T\n",
    "        positions.append(cur_positions)\n",
    "    \n",
    "    positions = np.asarray(positions)\n",
    "    return positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e0bcf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_vel(files_path,tp):\n",
    "    # extracts the velocities from the .dat file and filter for the given type\n",
    "\n",
    "    files = sorted(glob.glob(files_path))\n",
    "\n",
    "    velocities = []\n",
    "\n",
    "    for file in files:   \n",
    "        read_file = ReadData(file, \"SAMoS\")\n",
    "        read_data= read_file.data\n",
    "        data1 = read_data[read_data['type']==tp]\n",
    "        cur_velocities = np.stack((data1['vx'], data1['vy'], data1['vz'])).T\n",
    "        velocities.append(cur_velocities)\n",
    "    \n",
    "    velocities = np.asarray(velocities)\n",
    "    return velocities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f7d4a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_directors(files_path,tp):\n",
    "    # extracts the directors/orientation from the .dat file and filter for the given type\n",
    "\n",
    "    files = sorted(glob.glob(files_path))\n",
    "\n",
    "    directors = []\n",
    "\n",
    "    for file in files:   \n",
    "        read_file = ReadData(file, \"SAMoS\")\n",
    "        read_data= read_file.data\n",
    "        data1 = read_data[read_data['type']==tp]\n",
    "        cur_directors = np.stack((data1['nx'], data1['ny'], data1['nz'])).T\n",
    "        directors.append(cur_directors)\n",
    "    \n",
    "    directors = np.asarray(directors)\n",
    "    return directors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69cc192d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_particle_radii(files_path):\n",
    "    # extracts the particle radii from the .dat file and filter for the given type\n",
    "\n",
    "    files = sorted(glob.glob(files_path))\n",
    "    radii = []\n",
    "    for file in files:   \n",
    "        read_file = ReadData(file, \"SAMoS\")\n",
    "        data1= read_file.data\n",
    "        cur_radii = data1['radius']\n",
    "        radii.append(cur_radii)\n",
    "    \n",
    "    radii = np.asarray(radii)\n",
    "    return radii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f9f095f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\noutput_file_path = \"/data1/pabshettiwar/Simulation_Softwares/SAMOS_ABP/tumoroid_system_alignments/1000-morse/pair_nematic/Seed-5/xi_1.0_J_0.5_dr_0.01_abp-p_0.3_ma_2.50_mD_0.08/output_*.dat\"\\ndir_path = \\'/data1/pabshettiwar/Simulation_Softwares/SAMOS_ABP/tumoroid_system_alignments/1000-morse/pair_nematic/Seed-5/xi_1.0_J_0.5_dr_0.01_abp-p_0.3_ma_2.50_mD_0.08/\\'\\n\\nfiles = sorted(glob.glob(output_file_path))\\n\\npositions_ts = []\\n\\nfor i, file in enumerate(files):   \\n    read_file = ReadData(file, \"SAMoS\")\\n    data_read= read_file.data\\n\\n    # extract type 1 particle\\n    data_1 = data_read[data_read[\\'type\\']==1]\\n    position_cur = np.stack((data_1[\\'x\\'], data_1[\\'y\\']), axis = 1)    \\n    positions_ts.append(position_cur)\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "output_file_path = \"/data1/pabshettiwar/Simulation_Softwares/SAMOS_ABP/tumoroid_system_alignments/1000-morse/pair_nematic/Seed-5/xi_1.0_J_0.5_dr_0.01_abp-p_0.3_ma_2.50_mD_0.08/output_*.dat\"\n",
    "dir_path = '/data1/pabshettiwar/Simulation_Softwares/SAMOS_ABP/tumoroid_system_alignments/1000-morse/pair_nematic/Seed-5/xi_1.0_J_0.5_dr_0.01_abp-p_0.3_ma_2.50_mD_0.08/'\n",
    "\n",
    "files = sorted(glob.glob(output_file_path))\n",
    "\n",
    "positions_ts = []\n",
    "\n",
    "for i, file in enumerate(files):   \n",
    "    read_file = ReadData(file, \"SAMoS\")\n",
    "    data_read= read_file.data\n",
    "\n",
    "    # extract type 1 particle\n",
    "    data_1 = data_read[data_read['type']==1]\n",
    "    position_cur = np.stack((data_1['x'], data_1['y']), axis = 1)    \n",
    "    positions_ts.append(position_cur)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a549038",
   "metadata": {},
   "outputs": [],
   "source": [
    "import alphashape\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Polygon, MultiLineString, LineString, MultiPolygon\n",
    "from shapely.plotting import plot_polygon\n",
    "from pathlib import Path\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8c72641",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shape(points,alpha):\n",
    "    # uses alpha shape to obtain alpha shape and respective area, perimeter\n",
    "    \n",
    "    alpha_shape = alphashape.alphashape(points, alpha)\n",
    "    #area = alpha_shape.area\n",
    "    #perimeter = alpha_shape.length\n",
    "\n",
    "    return alpha_shape #, area, perimeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74243fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cells_2D(points):\n",
    "    # takes in the total points [(x,y), .. ] as arguments to plot\n",
    "    \n",
    "    x_points = points[0]\n",
    "    y_points = points[1]\n",
    "\n",
    "    fig,ax = plt.subplots(constrained_layout=True)\n",
    "    ax.scatter(x_points,y_points)\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    plt.gca().set_aspect('equal')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36e5e229",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_alphashape(shape, points,frame = 1, outer_points= False,  dir = Path.cwd()):\n",
    "    # arguments : alpha shape, original points, total number of time frames, directory to save output files(images) \n",
    "    \n",
    "    fig, ax = plt.subplots(constrained_layout=True)\n",
    "    ax.scatter(points.T[0], points.T[1], s=5)\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    ax.set_xlim(-50,50)\n",
    "    ax.set_ylim(-50,50)\n",
    "    plot_polygon(shape, ax=ax, add_points=outer_points, facecolor='orange', alpha = 0.5)\n",
    "    plt.savefig(os.path.join(dir, f\"tumor_alphashape_test_{frame:04d}.png\"), dpi = 100, format = 'png', )\n",
    "    plt.close()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4925957",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shape_index(peri, area):\n",
    "    # shape index measures closeness to circle\n",
    "    # si = perimeter/ 2* (pi* area)**1/2 \n",
    "    si = peri / (2* np.sqrt(np.pi * area))\n",
    "    return si\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abd52b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSD(positions:np.ndarray):\n",
    "    # simple msd calculations ==> |x(t) - x(0)|**2 for frame(t) and averaged over all particles for each frame i.e ensemble average\n",
    "    # there is no moving tau window used here  \n",
    "    msd = np.mean(np.sum((positions - positions[0,:,:][np.newaxis,:,:])**2, axis = 2), axis = 1)\n",
    "    return msd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4b01507",
   "metadata": {},
   "outputs": [],
   "source": [
    "def radius_of_gyration(positions):\n",
    "    # Calculates the radius of gyration\n",
    "    \n",
    "    N = np.shape(positions)[0]\n",
    "    sum_r = np.sum(positions, axis = 0)\n",
    "    sum_r2 = np.sum(np.sum(positions**2, axis=1))\n",
    "    rg_2 = sum_r2/N - np.sum(sum_r**2)/N**2\n",
    "    return np.sqrt(rg_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ae37eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def center_of_mass(positions):\n",
    "    # Caculates the center of mass\n",
    "    \n",
    "    N = np.shape(positions)[0]\n",
    "    sum_r = np.sum(positions,axis = 0)\n",
    "    return sum_r/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "413e7e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_invasion_radius_shape(positions, shape):\n",
    "    # takes in all positions of all the points and alpha shape\n",
    "    # Calculates the distance between com and boundary points and returns the maximum of the distances\n",
    "\n",
    "    if isinstance(shape, Polygon):\n",
    "        boundary_points = list(shape.exterior.coords)\n",
    "    elif isinstance(shape,LineString) or isinstance(shape, MultiLineString):\n",
    "        boundary_points = list(shape.coords)\n",
    "    \n",
    "    com = center_of_mass(positions)\n",
    "    dist_com = np.sum((boundary_points - com)**2, axis =1)**0.5\n",
    "    invasion_radius = np.max(dist_com)\n",
    "\n",
    "    return invasion_radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61ee4a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_invasion_radius(positions):\n",
    "    # Calculates the distane between farthest particle and center of mass\n",
    "    # returns this distance  \n",
    "\n",
    "    com = center_of_mass(positions)\n",
    "    dist_com = np.sum((positions - com)**2, axis =1)**0.5\n",
    "    invasion_radius = np.max(dist_com)\n",
    "\n",
    "    return invasion_radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1976a9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_boundary_length(shape):\n",
    "    # returns the boundary length for largest polygon structure\n",
    "\n",
    "    if isinstance(shape, Polygon):\n",
    "        boundary_length = shape.length\n",
    "        print(boundary_length)\n",
    "    elif isinstance(shape,MultiPolygon):\n",
    "        largest_poly = max(shape.geoms, key = lambda p:p.area)\n",
    "        boundary_length = largest_poly.length\n",
    "    \n",
    "    return boundary_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "107113ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vicsek_op(velocities, act_strength):\n",
    "    # obtains the instataneous vicsek order parameter\n",
    "    order_param = np.sum(velocities)/ (np.shape(velocities)[0] * act_strength )\n",
    "    return order_param "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac7c369a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit()\n",
    "def get_vicsek_director_op(directors):\n",
    "    # input all the n vectors (directors) of the particles and produces the global polar director\n",
    "    return np.sum(directors) / np.shape(directors)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a9cc4df5-7ee0-4f52-841c-0fadd724c053",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit()\n",
    "def kdelta(x,y):\n",
    "    if (x==y):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "@njit()\n",
    "def nvector(m):\n",
    "    n = np.absolute(m)\n",
    "    mx = max(n)\n",
    "    pos = 0\n",
    "    for i in range(len(n)):\n",
    "        if(mx==n[i]):\n",
    "            pos = i\n",
    "    return pos\n",
    "\n",
    "@njit(float64[:](float64[:],float64[:],float64[:]))\n",
    "def Qmethod(ux,uy,uz):\n",
    "    \n",
    "    Q = np.zeros((3,3),dtype=np.float64)\n",
    "    u = [ux,uy,uz]\n",
    "    \n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            for k in range(len(ux)):\n",
    "                Q[i][j]  = Q[i][j] + (3/2 * u[i][k] * u[j][k] - kdelta(i,j)/2) \n",
    "\n",
    "    Q = np.divide(Q , int(len(ux)))\n",
    "    \n",
    "    w,v = np.linalg.eigh(Q)\n",
    "    \n",
    "    n_vec_pos = nvector(w)\n",
    "    \n",
    "    n_vect2 = v[int(n_vec_pos)]\n",
    "    \n",
    "    #n_vect2_mag = np.sqrt(n_vect2[0]**2 + n_vect2[1]**2 + n_vect2[2]**2)\n",
    "    \n",
    "    n_vect2_mag = np.linalg.norm(n_vect2)\n",
    "    \n",
    "    n_vect2 = np.divide(n_vect2 , n_vect2_mag) \n",
    "    \n",
    "    return n_vect2\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "34a2dee2-dbc4-430c-b087-01cf06554467",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit()\n",
    "def calOrder(n_vt,ux,uy,uz):\n",
    "    # calculates the magnitude of the Q-tensor order parameter\n",
    "    S = 0\n",
    "    for i in range(len(ux)):\n",
    "        S = S + ( (3/2)*(np.dot(n_vt,np.array([ux[i],uy[i],uz[i]]))**2) -1/2 )\n",
    "    S = S/int(len(ux))\t\n",
    "    \n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "138e4aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_file(data, dir):\n",
    "    # pass the dictionary for the data and saving directory/location\n",
    "    # if successful return true otherwise false\n",
    "    try:\n",
    "        with open(os.path.join(dir, \"analysis_data.npz\"), \"wb\") as fil:\n",
    "            np.savez(fil, traj = data[\"trajectory\"], vel = data[\"velocities\"], msd = data[\"msd\"], rog =data[\"rog\"], vicsek =data[\"vicsek_op\"],\n",
    "                     inv_rad = data[\"invasion_radius\"], boundary_len = data[\"boundary_length\"])\n",
    "    except:\n",
    "        print(\"\\n Error,  Data not saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "59887a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(data, type, dir, **kwargs):\n",
    "    try:\n",
    "        with open(os.path.join(dir, f\"{type}_data.npz\"), \"wb\") as fil:\n",
    "            np.savez(fil, data=data, **kwargs)\n",
    "            \n",
    "    except:\n",
    "        print(\"\\n Error, data not saved \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "97290a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_traj_shapes(traj, alpha, dir):\n",
    "\n",
    "    for frame in range(np.shape(traj)[0]):\n",
    "        points_cur = traj[frame]\n",
    "        a_shape = get_shape(points_cur, alpha)\n",
    "        # a_shape, area, perimeter = get_shape(points_cur, alpha)\n",
    "        plot_alphashape(a_shape, points_cur, frame = frame, outer_points= False, dir = dir ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b535760b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor dir in os.listdir(data_dir_path):\\n\\n    cur_path = os.path.join(data_dir_path, dir)\\n    \\n    cur_output_files = os.path.join(cur_path, 'output_*.dat')\\n    \\n    cur_traj = extract_positions(cur_output_files, tp=1)\\n\\n    if not os.path.isdir(os.path.join(cur_path, 'alpha_images')):\\n        os.mkdir(os.path.join(cur_path, 'alpha_images'))\\n    \\n    img_path = os.path.join(cur_path, 'alpha_images')\\n    \\n    generate_traj_shapes(cur_traj[:,:,:2], alpha, dir = img_path )\\n\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir_path = '/data1/pabshettiwar/Simulation_Softwares/SAMOS_ABP/tumoroid_system_alignments/1000-morse/pair_nematic/phase_diagram/new'\n",
    "alpha = 0.5\n",
    "'''\n",
    "for dir in os.listdir(data_dir_path):\n",
    "\n",
    "    cur_path = os.path.join(data_dir_path, dir)\n",
    "    \n",
    "    cur_output_files = os.path.join(cur_path, 'output_*.dat')\n",
    "    \n",
    "    cur_traj = extract_positions(cur_output_files, tp=1)\n",
    "\n",
    "    if not os.path.isdir(os.path.join(cur_path, 'alpha_images')):\n",
    "        os.mkdir(os.path.join(cur_path, 'alpha_images'))\n",
    "    \n",
    "    img_path = os.path.join(cur_path, 'alpha_images')\n",
    "    \n",
    "    generate_traj_shapes(cur_traj[:,:,:2], alpha, dir = img_path )\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df4d6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_path = '/disks/pi-henkes/pabshettiwar/1000-morse/pair_nematic/phase_diagram'\n",
    "alpha =0.5\n",
    "time = np.linspace(0, 2500, 1000)\n",
    "\n",
    "for dir in os.listdir(data_dir_path):\n",
    "\n",
    "    cur_path = os.path.join(data_dir_path, dir)\n",
    "\n",
    "    #if(os.path.isfile(os.path.join(cur_path, \"analysis_data.npz\"))):\n",
    "    #    continue\n",
    "\n",
    "    dir_name = str(os.path.basename(cur_path))\n",
    "\n",
    "    #if os.path.isdir(dir_name):\n",
    "    #    continue\n",
    "\n",
    "    srch = re.search('p_', dir_name)\n",
    "    span = list(srch.span())\n",
    "    \n",
    "    srh_end = span[-1]\n",
    "    act_strength = float(dir_name[srh_end:srh_end+3])\n",
    "    if(act_strength == 0.0):\n",
    "        act_strength = 0.05\n",
    "\n",
    "    cur_output_files = os.path.join(cur_path, 'output_*.dat')\n",
    "\n",
    "    cur_traj = extract_positions(cur_output_files, tp=1)\n",
    "    cur_vel = extract_vel(cur_output_files, tp=1)\n",
    "\n",
    "    # calculate MSD\n",
    "    msd_cur_ts = np.array(MSD(cur_traj[:]))\n",
    "\n",
    "    # Calculate Radius of Gyration\n",
    "    rog_ts = []\n",
    "\n",
    "    for i in range(np.shape(cur_traj[:])[0]):\n",
    "        rog = radius_of_gyration(cur_traj[i])\n",
    "        rog_ts.append(rog)\n",
    "    \n",
    "    rog_ts = np.array(rog_ts)\n",
    "    \n",
    "    # Calculate Vicsek order paramater\n",
    "    vicsek_op_ts = []\n",
    "\n",
    "    for i in range(np.shape(cur_vel[:])[0]):\n",
    "        vicsek_op = get_vicsek_op(cur_vel[i],act_strength)\n",
    "        vicsek_op_ts.append(vicsek_op)\n",
    "    \n",
    "    vicsek_op_ts = np.array(vicsek_op_ts)\n",
    "    \n",
    "    # Calculate the Invasion Radius\n",
    "    inv_radius_ts = []\n",
    "\n",
    "    for i in range(np.shape(cur_traj[:])[0]):\n",
    "        inv_rad = get_invasion_radius(cur_traj[i])\n",
    "        inv_radius_ts.append(inv_rad)\n",
    "\n",
    "    inv_radius_ts = np.array(inv_radius_ts)\n",
    "\n",
    "    # Get alpha shapes for trajectorycontinue\n",
    "    shapes_ts = []\n",
    "\n",
    "    for i in range(np.shape(cur_traj[:])[0]):\n",
    "        shape = get_shape(cur_traj[i][:][:2], alpha)\n",
    "        shapes_ts.append(shape)\n",
    "    \n",
    "\n",
    "    # Calculate the boundary length\n",
    "    boundary_len_ts = []\n",
    "\n",
    "    for i in range(np.shape(cur_traj[:])[0]):\n",
    "        shape = get_shape(cur_traj[i,:, :2], alpha)\n",
    "        boundary_len = shape.length\n",
    "        boundary_len_ts.append(boundary_len)\n",
    "    \n",
    "    boundary_len_ts = np.array(boundary_len_ts)\n",
    "\n",
    "    analysis_data = {\"trajectory\": cur_traj[:], \"velocities\": cur_vel[:], \"msd\":msd_cur_ts, \"rog\":rog_ts, \"vicsek_op\":vicsek_op_ts, \n",
    "                     \"invasion_radius\":inv_radius_ts, \"alpha_shapes\":shapes_ts, \"boundary_length\": boundary_len_ts }\n",
    "    \n",
    "\n",
    "    #save_file(analysis_data, dir = cur_path)\n",
    "    \n",
    "    save_data(msd_cur_ts, 'msd', dir= cur_path, time=time)\n",
    "    save_data(vicsek_op_ts, 'vicsek_op', dir= cur_path, time=time)\n",
    "    save_data(rog_ts, 'rog', dir= cur_path, time=time)\n",
    "    save_data(inv_radius_ts, 'invasion_radius', dir= cur_path, time=time)\n",
    "    save_data(boundary_len_ts, 'boundary_len', dir= cur_path, time=time)\n",
    "    \n",
    "\n",
    "    '''    \n",
    "    fig,ax = plt.subplots()\n",
    "    ax.loglog(msd_cur)\n",
    "    plt.savefig(os.path.join(cur_path, f\"msd_c.png\"), format= \"png\", dpi = 200)\n",
    "    plt.close()\n",
    "\n",
    "    fig,ax = plt.subplots()\n",
    "    ax.plot(rog_all)\n",
    "    plt.savefig(os.path.join(cur_path,f\"Radius_of_gyration_c.png\"), format=\"png\", dpi = 200)\n",
    "    plt.close()\n",
    "    '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c447cd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_analysis_data(file_name, dir_name):\n",
    "\n",
    "    msd_all = []\n",
    "    rog_all = []\n",
    "    inv_rad_all = []\n",
    "    vicsek_all = []\n",
    "    act_all = []\n",
    "    J_all=[]\n",
    "\n",
    "    for dir in sorted(os.listdir(dir_name)):\n",
    "        cur_path = os.path.join(dir_name, dir)\n",
    "\n",
    "        if not os.path.isdir(cur_path):\n",
    "            continue\n",
    "\n",
    "        cur_dir_name = str(os.path.basename(dir))\n",
    "        print(cur_dir_name)\n",
    "\n",
    "        # obtain the activity from name\n",
    "        search = re.search('p_', cur_dir_name)\n",
    "        if search:\n",
    "            end = search.span()[1]\n",
    "        \n",
    "        activity = float(cur_dir_name[end:end+3])\n",
    "        act_all.append(activity)\n",
    "\n",
    "\n",
    "        # obtain alignment strength from name of the directory\n",
    "        search2 = re.search('J_', cur_dir_name)\n",
    "        if search2:\n",
    "            end2 = search2.span()[1]\n",
    "\n",
    "        J = float(cur_dir_name[end2:end2+3])\n",
    "        J_all.append(J)\n",
    "\n",
    "        fil = open(os.path.join(cur_path,file_name), \"rb\") \n",
    "        analysis_data = np.load(fil)\n",
    "        msd = analysis_data['msd']\n",
    "        rog = analysis_data['rog']\n",
    "        inv_rad = analysis_data['inv_rad']\n",
    "        vicsek_op = analysis_data['vicsek']\n",
    "        \n",
    "        msd_all.append(msd)\n",
    "        rog_all.append(rog)\n",
    "        inv_rad_all.append(inv_rad)\n",
    "        vicsek_all.append(vicsek_op)\n",
    "        \n",
    "    \n",
    "\n",
    "    fig,ax = plt.subplots()\n",
    "    plt.title(\"MSD as function of activity\")\n",
    "    for l in range(len(msd_all)):\n",
    "        ax.loglog(msd_all[l], label= f\"p = {act_all[l]}, J = {J_all[l]}\")\n",
    "    plt.legend()    \n",
    "    plt.xlabel(\"time\")\n",
    "    plt.ylabel(\"MSD\")\n",
    "    plt.savefig(os.path.join(dir_name, f\"msd_all.png\"), format= \"png\", dpi = 400)\n",
    "    plt.close()\n",
    "\n",
    "    fig,ax = plt.subplots()\n",
    "    plt.title(\"Radius_of_gyration\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "985b8ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xi_1.0_J_0.5_dr_0.01_abp-p_0.3_ma_2.50_mD_0.08\n",
      "xi_1.0_J_0.5_dr_0.01_abp-p_0.5_ma_2.50_mD_0.08\n",
      "xi_1.0_J_0.5_dr_0.01_abp-p_0.7_ma_2.50_mD_0.08\n",
      "xi_1.0_J_0.8_dr_0.01_abp-p_0.3_ma_2.50_mD_0.08\n",
      "xi_1.0_J_0.8_dr_0.01_abp-p_0.5_ma_2.50_mD_0.08\n",
      "xi_1.0_J_0.8_dr_0.01_abp-p_0.7_ma_2.50_mD_0.08\n"
     ]
    }
   ],
   "source": [
    "plot_analysis_data(\"analysis_data.npz\",\"/data1/pabshettiwar/Simulation_Softwares/SAMOS_ABP/tumoroid_system_alignments/1000-morse/pair_polar/Seed-5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f349ebf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
